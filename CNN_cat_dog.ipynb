{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Introduction\n",
        "\n",
        "The data we are working with is from Will Cukierski, Dogs vs. Cats Redux: Kernels Edition on Kaggle: https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition\n",
        "\n",
        "It is a collection of images of cats and dogs. Our goal here is to create a CNN model that can effectively distinguish whether a given image is a cat or a dog. \n",
        "\n",
        "In the training data we have a total of 25,000 images. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data load / Libraries load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hIC1jzmQmU9",
        "outputId": "821507e3-f34c-4670-adcb-97439e91fa86"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import seaborn as sns\n",
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score, recall_score\n",
        "\n",
        "print('TensorFlow version - ',tf.__version__)\n",
        "# Check if GPU is available\n",
        "gpu_available = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "if gpu_available:\n",
        "    print(\"TensorFlow is installed as GPU version.\")\n",
        "else:\n",
        "    print(\"TensorFlow is installed as CPU version.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9h7zqOwFcxci"
      },
      "outputs": [],
      "source": [
        "# training images\n",
        "# List all image paths\n",
        "train_paths = [os.path.join(\n",
        "    'data/cat&dog_data/train', f) for f in os.listdir(\n",
        "        'data/cat&dog_data/train') if f.endswith('.jpg')]\n",
        "\n",
        "# label 0 if cat and 1 if dog\n",
        "labels = [0 if 'cat' in os.path.basename(path) else 1 for path in train_paths]\n",
        "\n",
        "# Create DataFrame\n",
        "train_image = pd.DataFrame({'filename': train_paths, 'label': labels})\n",
        "\n",
        "# shuffle data\n",
        "train_image = train_image.sample(frac=1, random_state=33).reset_index(drop=True)\n",
        "\n",
        "# testing images\n",
        "# List all image paths\n",
        "test_path = [os.path.join(\n",
        "    'data/cat&dog_data/test', f) for f in os.listdir(\n",
        "        'data/cat&dog_data/test') if f.endswith('.jpg')]\n",
        "\n",
        "# Create DataFrame\n",
        "test_image = pd.DataFrame({'filename': test_path})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### We are using ImageDataGenerator to convert images to DataFrameIterator\n",
        "### We will split the data into 80% training and 20% validating. And the data are scaled using 255 pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n9LlBc4V8EJ",
        "outputId": "fef427cc-7564-4a92-b0a2-cec940440f82"
      },
      "outputs": [],
      "source": [
        "# prevent overfitting by rotating, and flipping the images\n",
        "train_gen = ImageDataGenerator(rescale = 1./255, rotation_range = 20,\n",
        "                               horizontal_flip=True,\n",
        "                               validation_split = 0.2)\n",
        "val_gen = ImageDataGenerator(rescale = 1./255, validation_split = 0.2)\n",
        "test_gen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "df_train = train_gen.flow_from_dataframe(\n",
        "    dataframe=train_image,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=128,\n",
        "    class_mode='raw',\n",
        "    subset='training',\n",
        "    seed = 33\n",
        ")\n",
        "\n",
        "df_val = val_gen.flow_from_dataframe(\n",
        "    dataframe=train_image,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=(150, 150),\n",
        "    batch_size = 128,\n",
        "    class_mode='raw',\n",
        "    subset='validation',\n",
        "    seed = 33,\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "df_test = test_gen.flow_from_dataframe(\n",
        "    dataframe=test_image,\n",
        "    x_col='filename',\n",
        "    y_col=None,  # No labels\n",
        "    target_size=(150, 150),\n",
        "    batch_size=128,\n",
        "    class_mode=None,  # Important: class_mode=None skips labels\n",
        "    shuffle=False      # Preserve order for submission\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Checking Data Dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qtn-Lgkarb35",
        "outputId": "0d87ea55-c346-4be2-b5ff-a16507afa93a"
      },
      "outputs": [],
      "source": [
        "# inspect df_train\n",
        "x_batch, y_batch = next(df_train)  # Get a batch of data from df_train\n",
        "print(x_batch.shape)\n",
        "print(y_batch.shape)\n",
        "print(np.min(x_batch), np.max(x_batch))\n",
        "print(np.unique(y_batch))  # See if labels are correct (0 and 1)\n",
        "\n",
        "# inspect df_val\n",
        "x_val_batch, y_val_batch = next(df_val)\n",
        "print(x_val_batch.shape)\n",
        "print(y_val_batch.shape)\n",
        "print(np.min(x_val_batch), np.max(x_val_batch))\n",
        "print(np.unique(y_val_batch))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Presentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "WRiey1uSkqKu",
        "outputId": "4f6c4c3e-86d7-418a-b7bc-5b7472c726f7"
      },
      "outputs": [],
      "source": [
        "# sample images\n",
        "plt.figure()\n",
        "f, axarr = plt.subplots(2,2)\n",
        "\n",
        "axarr[0,0].imshow(io.imread(train_image['filename'][20000]))\n",
        "axarr[0,1].imshow(io.imread(train_image['filename'][20887]))\n",
        "axarr[1,0].imshow(io.imread(train_image['filename'][1902]))\n",
        "axarr[1,1].imshow(io.imread(train_image['filename'][4719]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9Zl5B3-rk4E",
        "outputId": "c3e42066-febe-4332-eab7-46eb4fe0b1c8"
      },
      "outputs": [],
      "source": [
        "train_image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "nf8WFF6grYtt",
        "outputId": "71589e2c-1d50-43bf-a064-c7adccba5412"
      },
      "outputs": [],
      "source": [
        "# label distribution\n",
        "sns.histplot(train_image['label'])\n",
        "plt.title('Distribution of Labels in Training Data')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Since this is an image data, and all images are being used to train the model. There is not much EDA to be done. \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview of findings and next steps\n",
        "\n",
        "We are intrested in testing these parameters in our models:\n",
        "- Model Depth - Increasing the number of convolutional layers from 2 to 3.\n",
        "- Batch Size - Comparing a batch size of 128 versus 64.\n",
        "- Regularization - Incorporating L2 regularization (with a factor of 0.001) to assess its effect on overfitting.\n",
        "\n",
        "All models maintained a consistent dropout rate of 0.4 in the dense layer and used the Adam optimizer with default learning rates (0.001)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 1 Architecture"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2 Conv2D layers (32, 64 nodes), Dropout = 0.4 at after Dense layer, default learning rate at 0.001, Adam potimizer, batch size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_1 = models.Sequential([\n",
        "    keras.Input(shape=(150,150,3)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_1.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint('model_1.keras', save_best_only=True)\n",
        "]\n",
        "\n",
        "print('start model 1 training')\n",
        "start_time = time.time()\n",
        "\n",
        "history = model_1.fit(\n",
        "    df_train,\n",
        "    epochs=10,\n",
        "    validation_data=df_val,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Model 1 training time: {(end_time - start_time)/60:.2f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### After 10 epochs, the validation accuracy is catching up with the training accuracy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 2 Architecture"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3 Conv2D layers (32, 64, and 128 nodes), Dropout = 0.4 at after Dense layer, default learning rate at 0.001, Adam potimizer, batch size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_2 = models.Sequential([\n",
        "    keras.Input(shape=(150,150,3)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_2.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint('model_2.keras', save_best_only=True)\n",
        "]\n",
        "\n",
        "print('start model 2 training')\n",
        "start_time = time.time()\n",
        "\n",
        "history = model_2.fit(\n",
        "    df_train,\n",
        "    epochs=10,\n",
        "    validation_data=df_val,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Model 2 training time: {(end_time - start_time)/60:.2f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### After 10 epochs, the validation accuracy shows sign of overfitting"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 3 Architecture"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3 Conv2D layers (32, 64, and 128 nodes), Dropout = 0.4 at after Dense layer, default learning rate at 0.001, Adam potimizer, batch size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = train_gen.flow_from_dataframe(\n",
        "    dataframe=train_image,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=64,\n",
        "    class_mode='raw',\n",
        "    subset='training',\n",
        "    seed = 33\n",
        ")\n",
        "\n",
        "df_val = val_gen.flow_from_dataframe(\n",
        "    dataframe=train_image,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=(150, 150),\n",
        "    batch_size = 64,\n",
        "    class_mode='raw',\n",
        "    subset='validation',\n",
        "    seed = 33,\n",
        "    shuffle = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "HBM_u-Fjo-Ra",
        "outputId": "a3a11fbf-8ff3-414e-fa06-383d18da0b26"
      },
      "outputs": [],
      "source": [
        "model_3 = models.Sequential([\n",
        "    keras.Input(shape=(150,150,3)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                  kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu',\n",
        "                  kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu',\n",
        "                  kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_3.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "PIUXwc-BDSDg",
        "outputId": "2a5aa846-c1fc-4917-9125-1f8735ea4c56"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint('model_3.keras', save_best_only=True)\n",
        "]\n",
        "\n",
        "print('start model 3 training')\n",
        "start_time = time.time()\n",
        "\n",
        "history = model_3.fit(\n",
        "    df_train,\n",
        "    epochs=10,\n",
        "    validation_data=df_val,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Model 3 training time: {(end_time - start_time)/60:.2f} minutes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQWcBrzpVgut"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### After 10 epochs, the validation accuracy shows sign of overfitting"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_1 = tf.keras.models.load_model('model_1.keras')\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_1.evaluate(df_val)\n",
        "\n",
        "y_pred_prob = model_1.predict(df_val).ravel()  # predicted probabilities\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "y_true = df_val.labels\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix for Model 1\")\n",
        "plt.show()\n",
        "\n",
        "print(f'The accuracy score of Model 1 is: {accuracy_score(y_true, y_pred)}')\n",
        "print(f'The recall score of Model 1 is: {recall_score(y_true, y_pred)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC curve (area = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver Operating Characteristic (ROC) for model 1\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the saved model from the .keras file\n",
        "model_2 = tf.keras.models.load_model('model_2.keras')\n",
        "\n",
        "# Optionally, display the model architecture\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0G3q7UAHD1r"
      },
      "outputs": [],
      "source": [
        "model_2.evaluate(df_val)\n",
        "\n",
        "y_pred_prob = model_2.predict(df_val).ravel()  # predicted probabilities\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "y_true = df_val.labels\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix for Model 2\")\n",
        "plt.show()\n",
        "\n",
        "print(f'The accuracy score of Model 2 is: {accuracy_score(y_true, y_pred)}')\n",
        "print(f'The recall score of Model 2 is: {recall_score(y_true, y_pred)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC curve (area = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver Operating Characteristic (ROC) for model 2\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the saved model from the .keras file\n",
        "model_3 = tf.keras.models.load_model('model_3.keras')\n",
        "\n",
        "# Optionally, display the model architecture\n",
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_3.evaluate(df_val)\n",
        "\n",
        "y_pred_prob = model_3.predict(df_val).ravel()  # predicted probabilities\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "y_true = df_val.labels\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix for Model 3\")\n",
        "plt.show()\n",
        "\n",
        "print(f'The accuracy score of Model 3 is: {accuracy_score(y_true, y_pred)}')\n",
        "print(f'The recall score of Model 3 is: {recall_score(y_true, y_pred)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC curve (area = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver Operating Characteristic (ROC) for model 3\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Overview\n",
        "\n",
        "model 1\n",
        "- batch size = 128\n",
        "- Conv2D layers = 2\n",
        "- learning_rate = 0.001 (default)\n",
        "- drop out = 0.4 at Dense\n",
        "- runtime = 39 min\n",
        "- Eval = loss: 0.3988 - accuracy: 0.8198\n",
        "\n",
        "model 2\n",
        "- batch size = 128\n",
        "- Conv2D layers = 3\n",
        "- learning_rate = 0.001 (default)\n",
        "- drop out = 0.4 at Dense\n",
        "- runtime = 49 min\n",
        "- Eval =  loss: 0.3568 - accuracy: 0.8540\n",
        "\n",
        "model 3\n",
        "- batch size = 64\n",
        "- Conv2D layers = 3\n",
        "- learning_rate = 0.001 (default)\n",
        "- drop out = 0.4 at Dense\n",
        "- l2 regularization = 0.001\n",
        "- wider network\n",
        "- runtime: 51 min\n",
        "- Eval: loss: 0.4198 - accuracy: 0.8532"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_1 = tf.keras.models.load_model('model_1.keras')\n",
        "\n",
        "pred_probs = model_1.predict(df_test).ravel()\n",
        "\n",
        "# Convert filename (e.g., \"1.jpg\") to integer image id (1)\n",
        "test_image['image id'] = test_image['filename'].apply(lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_image['image id'],\n",
        "    'label': pred_probs\n",
        "})\n",
        "\n",
        "\n",
        "submission_df.sort_values('id', inplace=True)\n",
        "submission_df.to_csv('~/Desktop/submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_2 = tf.keras.models.load_model('model_2.keras')\n",
        "\n",
        "pred_probs = model_2.predict(df_test).ravel()\n",
        "\n",
        "# Convert filename (e.g., \"1.jpg\") to integer image id (1)\n",
        "test_image['image id'] = test_image['filename'].apply(lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_image['image id'],\n",
        "    'label': pred_probs\n",
        "})\n",
        "\n",
        "\n",
        "submission_df.sort_values('id', inplace=True)\n",
        "submission_df.to_csv('~/Desktop/submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_3 = tf.keras.models.load_model('model_3.keras')\n",
        "\n",
        "pred_probs = model_3.predict(df_test).ravel()\n",
        "\n",
        "# Convert filename (e.g., \"1.jpg\") to integer image id (1)\n",
        "test_image['image id'] = test_image['filename'].apply(lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_image['image id'],\n",
        "    'label': pred_probs\n",
        "})\n",
        "\n",
        "\n",
        "submission_df.sort_values('id', inplace=True)\n",
        "submission_df.to_csv('~/Desktop/submission.csv', index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reference\n",
        "\n",
        "     Will Cukierski. 2016. Dogs vs. Cats Redux: Kernels Edition. Kaggle. \n",
        "https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition. \n",
        "\n",
        "     \n",
        "     Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, et al. 2015. TensorFlow: Large-scale machine learning on heterogeneous systems. Software available from tensorflow.org\n",
        "https://www.tensorflow.org/ "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
