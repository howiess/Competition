{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import optuna \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizaiton is the practice of breaking sentences into individual words while considering punctuations within the sentence. It is able to break long words into prefix, roots, suffix, and etc. to maximize the ability for computer to recognize rare words by analyzing its Morphological meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', ',', 'world', '!', 'isn', \"'\", 't', 'it', 'amazing', 'how', 'language', 'works', '?', 'consider', 'this', ':', 'mr', '.', 'o', \"'\", 'connor', '—', 'who', 'famously', 'said', ',', \"'\", 'language', ',', 'in', 'all', 'its', 'messy', 'glory', ',', 'defines', 'our', 'reality', '!', \"'\", '—', 'often', 'challenged', 'conventional', 'grammar', 'rules', '.', 'in', 'fact', ',', 'when', 'you', 'read', ':', \"'\", 'wait', '—', 'what', '?', 'really', '?', '!', \"'\", 'you', 'notice', 'that', 'pun', '##ct', '##uation', ',', 'quotes', ',', 'dash', '##es', ',', 'and', 'ex', '##cl', '##ama', '##tion', 'points', 'all', 'serve', 'specific', 'roles', '.', '(', 'yes', ',', 'even', 'parentheses', 'add', 'context', '.', ')', 'token', '##ization', 'helps', 'break', 'down', 'such', 'complex', 'sentences', 'into', 'individual', ',', 'manage', '##able', 'token', '##s', 'for', 'further', 'processing', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "text = \"Hello, world! Isn't it amazing how language works? Consider this: Mr. O'Connor—who famously said, 'Language, in all its messy glory, defines our reality!'—often challenged conventional grammar rules. In fact, when you read: 'Wait—what? Really?!' you notice that punctuation, quotes, dashes, and exclamation points all serve specific roles. (Yes, even parentheses add context.) Tokenization helps break down such complex sentences into individual, manageable tokens for further processing.\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Corpus Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'data/train-00000-of-00001-ad33ea7d240dcb80.parquet', 'validation': 'data/validation-00000-of-00001-a108f2216fa73659.parquet', 'test': 'data/test-00000-of-00001-9696555e053ff5e2.parquet'}\n",
    "corpus_train = pd.read_parquet(\"hf://datasets/Shayanvsf/US_Airline_Sentiment/\" + splits[\"train\"])\n",
    "corpus_val = pd.read_parquet(\"hf://datasets/Shayanvsf/US_Airline_Sentiment/\" + splits[\"validation\"])\n",
    "corpus_test = pd.read_parquet(\"hf://datasets/Shayanvsf/US_Airline_Sentiment/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "airline_sentiment:\n",
    "This column likely represents a normalized sentiment score for each tweet. For example, a value closer to 1 might indicate positive sentiment, while a value closer to 0 might indicate negative sentiment. In some cases, it could also be interpreted as the probability that the tweet is positive (or negative), depending on how the model is designed.\n",
    "\n",
    "airline_sentiment_confidence:\n",
    "This column indicates the model's confidence in its sentiment prediction. A value near 1 means the model is very sure about the sentiment (whether positive or negative) it has assigned, while a value closer to 0 means the prediction is less certain.\n",
    "\n",
    "negative_reason_confidence:\n",
    "This column is likely relevant only when a tweet is classified as negative. It measures how confident the model is in identifying a specific reason for the negative sentiment (such as delays, poor service, etc.). Again, a value closer to 1 indicates high confidence that the reason it selected accurately explains the negativity expressed in the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all text into lower case characters \n",
    "corpus_train['text'] = corpus_train['text'].apply(lambda x: x.lower())\n",
    "corpus_val['text'] = corpus_val['text'].apply(lambda x: x.lower())\n",
    "corpus_test['text'] = corpus_test['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "airline_sentiment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "airline_sentiment_confidence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "negativereason_confidence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4c1cb1af-5a21-4102-b63f-e83bf6afc9d1",
       "rows": [
        [
         "0",
         "0",
         "1.0",
         "1.0",
         "@united thanks for causing us to miss our connection and now a 6hour delay #flydeltanexttime"
        ],
        [
         "1",
         "1",
         "1.0",
         null,
         "@united thank you. any help is appreciated."
        ],
        [
         "2",
         "0",
         "0.7179",
         "0.7179",
         "@usairways i ask for reimbursement maybe miles added to my account for my inconvenience and for the money that i had to spend"
        ],
        [
         "3",
         "0",
         "1.0",
         "0.6558",
         "@united annnnddddd i'm going to lose my first class seat on the flight they shuffle me to"
        ],
        [
         "4",
         "0",
         "1.0",
         "0.6654",
         "@americanair 4285. apparently we’re told, staff on the ground keep promising to come and they don’t."
        ],
        [
         "5",
         "0",
         "1.0",
         "1.0",
         "@united i did. the ac went on for about 20 minutes before returning to the mojave desert. #pressurecooker #heattrap"
        ],
        [
         "6",
         "0",
         "1.0",
         "1.0",
         "@southwestair i lost my luggage. my birthday wish is to find my luggage."
        ],
        [
         "7",
         "0",
         "1.0",
         "0.6736",
         "@usairways been on hold 2.5 hours now! system hung up on me twice after an hour holding. :(  trying 2 correct online flight booking problems error. #unhappy"
        ],
        [
         "8",
         "0",
         "1.0",
         "1.0",
         "@usairways on hold for 2 hours now have been calling since monday! i have a flight today need help now!!! #worst #noexcusesaccepted"
        ],
        [
         "9",
         "0",
         "1.0",
         "1.0",
         "@americanair don't worry you won't steal my money again"
        ],
        [
         "10",
         "0",
         "1.0",
         "1.0",
         "@united late flight to denver, late flight to newark...let's not even get into the disaster that was checking bags. unacceptable."
        ],
        [
         "11",
         "0",
         "1.0",
         "0.6578",
         "@united i have been denied. not sure how you charge $150 one way then $25 on way hime"
        ],
        [
         "12",
         "0",
         "1.0",
         "1.0",
         "@usairways thanks, but you can't. my flight was cancelled flightled for \"maintenance\" reasons, and the next available flight was too late flight for me."
        ],
        [
         "13",
         "0",
         "1.0",
         "1.0",
         "@united why? so i can waste more of time on this airline to get an automated message? disappointing as always."
        ],
        [
         "14",
         "0",
         "1.0",
         "0.697",
         "@united i will! on @americanair @southwestair @delta or @jetblue  all of which will be getting my business. #unfriendlyskies #unbelievable"
        ],
        [
         "15",
         "0",
         "1.0",
         "0.6883",
         "@americanair yes. just sayin' that was a particularly poorly handled situation."
        ],
        [
         "16",
         "0",
         "1.0",
         "0.6742",
         "@americanair 30 minutes flight from okc and then make us wait, 30 minutes cause the gate isn't empty.  #epicfail #poorplanning"
        ],
        [
         "17",
         "1",
         "0.6875",
         null,
         "@jetblue i did see that! working on picking up a trip or two as we type."
        ],
        [
         "18",
         "0",
         "1.0",
         "1.0",
         "@americanair @emrey35 but it says your agents are too busy and to try back late flightr???"
        ],
        [
         "19",
         "0",
         "1.0",
         "0.6659",
         "@united wifi wasn't working onboard.alerted attendant re socket.you sent me to a hotel for 24 hours with 7$ vouchers??no wifi at hotel"
        ],
        [
         "20",
         "1",
         "1.0",
         null,
         "@united we had a wonderful flight attendant named leah that was with us from lga to den, then den to anchorage!"
        ],
        [
         "21",
         "0",
         "1.0",
         "1.0",
         "@americanair your dca baggage claim employees should realize a please, a thank you and an apology can go a long way #customerservice #dca"
        ],
        [
         "22",
         "0",
         "0.6939",
         "0.3469",
         "@southwestair how does your pre boarding process work? basically anyone who doesn't want to wait their turn can get a slip?"
        ],
        [
         "23",
         "0",
         "1.0",
         "0.6609",
         "@southwestair well i had a car &amp; free place 2 stay had i known unacceptable treatment from spvsr. sally in cleveland. #disappointed"
        ],
        [
         "24",
         "0",
         "0.6319",
         "0.6319",
         "@southwestair not if its travel credit you used to buy and it expires on the day you find a lower rate"
        ],
        [
         "25",
         "0",
         "1.0",
         "0.696",
         "@united wanted to, but you cancelled flightled my tickets.... they were too special i guess even for united."
        ],
        [
         "26",
         "1",
         "0.6676",
         "0.0",
         "@southwestair your crew on 3138 is doing a great job of keeping everyone informed during the delays #givethemraises"
        ],
        [
         "27",
         "0",
         "1.0",
         "0.6882",
         "@united just tried to log in and was told e-mail log in not currently available"
        ],
        [
         "28",
         "1",
         "1.0",
         null,
         "@southwestair all's well. i got comped with multiple other bags which just made my day! http://t.co/1aavvoreph"
        ],
        [
         "29",
         "0",
         "1.0",
         "0.6823",
         "@southwestair first you had a good idea thatthis would happen and did not cancelled flight it earlier, then very amateurish that there was no plan."
        ],
        [
         "30",
         "1",
         "0.3414",
         "0.0",
         "@united when are you coming back to @iflyoakland? you have a huge east bay customer base due to sfo and *i* miss you!"
        ],
        [
         "31",
         "0",
         "1.0",
         "0.6845",
         "@united waiting on plane so long missed my connecting flight it left early. that's the last flight out tonight. help http://t.co/hbsj2sf17h"
        ],
        [
         "32",
         "1",
         "0.6481",
         null,
         "@southwestair telling my fam in vegas now. :)"
        ],
        [
         "33",
         "0",
         "1.0",
         "1.0",
         "@united is amazing how hard is to talk with customer service! !!"
        ],
        [
         "34",
         "0",
         "1.0",
         "0.6667",
         "@united that guy really has no customer service clue.could have spent effort clearing bins for rollerboards instead of art projects in mine!"
        ],
        [
         "35",
         "0",
         "0.65",
         "0.3609",
         "@southwestair my husband is responding to him and he insist to remove him from the seat. btw signs are in both english and spanish."
        ],
        [
         "36",
         "0",
         "1.0",
         "1.0",
         "@united i hope so but i've received no help so far. i've been on hold for more than an hour. can someone speak to me?"
        ],
        [
         "37",
         "0",
         "1.0",
         "0.6952",
         "@usairways thank you. the website crashing for me."
        ],
        [
         "38",
         "1",
         "1.0",
         null,
         "thanks to @southwestair , i get to go to the #destinationdragons @imaginedragons show this weekend in utah @velourlive  !!! #thankyou"
        ],
        [
         "39",
         "0",
         "1.0",
         "0.6646",
         "@americanair i've been in line for over half hour trying to see a representative, now i might even miss the next flight too, unacceptable"
        ],
        [
         "40",
         "1",
         "1.0",
         null,
         "@united flt 912. capt herman is amazing! came out before flight to play \"ask the captain anything.\" wonderful ambassador to the airline!!"
        ],
        [
         "41",
         "0",
         "1.0",
         "0.6469",
         "@united your new mileage policy is awful. before, i might have paid slightly more for united because of miles. now there's no difference."
        ],
        [
         "42",
         "0",
         "1.0",
         "1.0",
         "@usairways 2 hours on hold. still no answer. horrible."
        ],
        [
         "43",
         "1",
         "0.3476",
         "0.0",
         "@southwestair just go ahead and start the scavenger hunt after 5 pm today when work is over ;) #destinationdragons"
        ],
        [
         "44",
         "0",
         "0.6907",
         "0.3711",
         "@southwestair i couldn't fly you today &amp; it made the trip harder + had to pay for my checked bag. #devotedyyours but for today. :("
        ],
        [
         "45",
         "0",
         "1.0",
         "0.6289",
         "@usairways i will never fly @usairways again"
        ],
        [
         "46",
         "1",
         "1.0",
         null,
         "@usairways thanks! http://t.co/pd7r1ll6re"
        ],
        [
         "47",
         "0",
         "0.6476",
         "0.6476",
         "@jetblue i don't know- no one would tell me where they were coming from - i would guess so as that's where we had all the changes to flights"
        ],
        [
         "48",
         "1",
         "0.6858",
         "0.0",
         "@virginamerica another perfect flight.   how come on your planes,  the sun visors can stay down?  other carriers make you raise them?"
        ],
        [
         "49",
         "0",
         "1.0",
         "0.6695",
         "@jetblue oh right! me and hundred people arrived back to the same gate we left minutes ago in sdq http://t.co/7gb0hgw51t"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 8078
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@united thanks for causing us to miss our conn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@united thank you. any help is appreciated.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>@usairways i ask for reimbursement maybe miles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>@united annnnddddd i'm going to lose my first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6654</td>\n",
       "      <td>@americanair 4285. apparently we’re told, staf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8073</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@americanair my ex-boyfriend picks up my calls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8074</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@united i send an email about my bad experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8075</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6448</td>\n",
       "      <td>@virginamerica you are failing your customers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8076</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6649</td>\n",
       "      <td>@americanair your rubbish at social media! in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8077</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6947</td>\n",
       "      <td>0.3579</td>\n",
       "      <td>@united @delongerry ual sucks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8078 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment  airline_sentiment_confidence  \\\n",
       "0                     0                        1.0000   \n",
       "1                     1                        1.0000   \n",
       "2                     0                        0.7179   \n",
       "3                     0                        1.0000   \n",
       "4                     0                        1.0000   \n",
       "...                 ...                           ...   \n",
       "8073                  0                        1.0000   \n",
       "8074                  0                        1.0000   \n",
       "8075                  0                        1.0000   \n",
       "8076                  0                        1.0000   \n",
       "8077                  0                        0.6947   \n",
       "\n",
       "      negativereason_confidence  \\\n",
       "0                        1.0000   \n",
       "1                           NaN   \n",
       "2                        0.7179   \n",
       "3                        0.6558   \n",
       "4                        0.6654   \n",
       "...                         ...   \n",
       "8073                     1.0000   \n",
       "8074                     1.0000   \n",
       "8075                     0.6448   \n",
       "8076                     0.6649   \n",
       "8077                     0.3579   \n",
       "\n",
       "                                                   text  \n",
       "0     @united thanks for causing us to miss our conn...  \n",
       "1           @united thank you. any help is appreciated.  \n",
       "2     @usairways i ask for reimbursement maybe miles...  \n",
       "3     @united annnnddddd i'm going to lose my first ...  \n",
       "4     @americanair 4285. apparently we’re told, staf...  \n",
       "...                                                 ...  \n",
       "8073  @americanair my ex-boyfriend picks up my calls...  \n",
       "8074  @united i send an email about my bad experienc...  \n",
       "8075  @virginamerica you are failing your customers ...  \n",
       "8076  @americanair your rubbish at social media! in ...  \n",
       "8077                      @united @delongerry ual sucks  \n",
       "\n",
       "[8078 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# tokenize training text\n",
    "corpus_train['text'] = corpus_train['text'].apply(lambda x: tokenizer(x, truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values in negativereason_confidence variable\n",
    "corpus_train['negativereason_confidence'] = corpus_train['negativereason_confidence'].fillna(0)\n",
    "corpus_val['negativereason_confidence'] = corpus_val['negativereason_confidence'].fillna(0)\n",
    "corpus_test['negativereason_confidence'] = corpus_test['negativereason_confidence'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "airline_sentiment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "airline_sentiment_confidence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "negativereason_confidence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4dccfa03-d252-4374-9535-1fdc36ec0a9d",
       "rows": [
        [
         "0",
         "0",
         "1.0",
         "1.0",
         "{'input_ids': [101, 1030, 2142, 4283, 2005, 4786, 2149, 2000, 3335, 2256, 4434, 1998, 2085, 1037, 1020, 6806, 3126, 8536, 1001, 4875, 9247, 5794, 10288, 6916, 4168, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "1",
         "1",
         "1.0",
         "0.0",
         "{'input_ids': [101, 1030, 2142, 4067, 2017, 1012, 2151, 2393, 2003, 12315, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "2",
         "0",
         "0.7179",
         "0.7179",
         "{'input_ids': [101, 1030, 3915, 4313, 14035, 1045, 3198, 2005, 24964, 14905, 28393, 3672, 2672, 2661, 2794, 2000, 2026, 4070, 2005, 2026, 4297, 2239, 8159, 13684, 1998, 2005, 1996, 2769, 2008, 1045, 2018, 2000, 5247, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "3",
         "0",
         "1.0",
         "0.6558",
         "{'input_ids': [101, 1030, 2142, 5754, 10695, 14141, 14141, 2094, 1045, 1005, 1049, 2183, 2000, 4558, 2026, 2034, 2465, 2835, 2006, 1996, 3462, 2027, 23046, 2033, 2000, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "4",
         "0",
         "1.0",
         "0.6654",
         "{'input_ids': [101, 1030, 25988, 4313, 4413, 27531, 1012, 4593, 2057, 1521, 2128, 2409, 1010, 3095, 2006, 1996, 2598, 2562, 10015, 2000, 2272, 1998, 2027, 2123, 1521, 1056, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "5",
         "0",
         "1.0",
         "1.0",
         "{'input_ids': [101, 1030, 2142, 1045, 2106, 1012, 1996, 9353, 2253, 2006, 2005, 2055, 2322, 2781, 2077, 4192, 2000, 1996, 9587, 3900, 3726, 5532, 1012, 1001, 3778, 3597, 11045, 2099, 1001, 3684, 6494, 2361, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "6",
         "0",
         "1.0",
         "1.0",
         "{'input_ids': [101, 1030, 4943, 11215, 1045, 2439, 2026, 17434, 1012, 2026, 5798, 4299, 2003, 2000, 2424, 2026, 17434, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "7",
         "0",
         "1.0",
         "0.6736",
         "{'input_ids': [101, 1030, 3915, 4313, 14035, 2042, 2006, 2907, 1016, 1012, 1019, 2847, 2085, 999, 2291, 5112, 2039, 2006, 2033, 3807, 2044, 2019, 3178, 3173, 1012, 1024, 1006, 2667, 1016, 6149, 3784, 3462, 21725, 3471, 7561, 1012, 1001, 12511, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "8",
         "0",
         "1.0",
         "1.0",
         "{'input_ids': [101, 1030, 3915, 4313, 14035, 2006, 2907, 2005, 1016, 2847, 2085, 2031, 2042, 4214, 2144, 6928, 999, 1045, 2031, 1037, 3462, 2651, 2342, 2393, 2085, 999, 999, 999, 1001, 5409, 1001, 2053, 10288, 7874, 22447, 9468, 23606, 2098, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "9",
         "0",
         "1.0",
         "1.0",
         "{'input_ids': [101, 1030, 25988, 4313, 2123, 1005, 1056, 4737, 2017, 2180, 1005, 1056, 8954, 2026, 2769, 2153, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "10",
         "0",
         "1.0",
         "1.0",
         "{'input_ids': [101, 1030, 2142, 2397, 3462, 2000, 7573, 1010, 2397, 3462, 2000, 12948, 1012, 1012, 1012, 2292, 1005, 1055, 2025, 2130, 2131, 2046, 1996, 7071, 2008, 2001, 9361, 8641, 1012, 21873, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "11",
         "0",
         "1.0",
         "0.6578",
         "{'input_ids': [101, 1030, 2142, 1045, 2031, 2042, 6380, 1012, 2025, 2469, 2129, 2017, 3715, 1002, 5018, 2028, 2126, 2059, 1002, 2423, 2006, 2126, 2032, 2063, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "12",
         "0",
         "1.0",
         "1.0",
         "{'input_ids': [101, 1030, 3915, 4313, 14035, 4283, 1010, 2021, 2017, 2064, 1005, 1056, 1012, 2026, 3462, 2001, 8014, 3462, 3709, 2005, 1000, 6032, 1000, 4436, 1010, 1998, 1996, 2279, 2800, 3462, 2001, 2205, 2397, 3462, 2005, 2033, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "13",
         "0",
         "1.0",
         "1.0",
         "{'input_ids': [101, 1030, 2142, 2339, 1029, 2061, 1045, 2064, 5949, 2062, 1997, 2051, 2006, 2023, 8582, 2000, 2131, 2019, 12978, 4471, 1029, 15640, 2004, 2467, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "14",
         "0",
         "1.0",
         "0.697",
         "{'input_ids': [101, 1030, 2142, 1045, 2097, 999, 2006, 1030, 25988, 4313, 1030, 4943, 11215, 1030, 7160, 2030, 1030, 6892, 16558, 5657, 2035, 1997, 2029, 2097, 2022, 2893, 2026, 2449, 1012, 1001, 4895, 19699, 9013, 18718, 23955, 2015, 1001, 23653, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "15",
         "0",
         "1.0",
         "0.6883",
         "{'input_ids': [101, 1030, 25988, 4313, 2748, 1012, 2074, 2360, 2378, 1005, 2008, 2001, 1037, 3391, 9996, 8971, 3663, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "16",
         "0",
         "1.0",
         "0.6742",
         "{'input_ids': [101, 1030, 25988, 4313, 2382, 2781, 3462, 2013, 7929, 2278, 1998, 2059, 2191, 2149, 3524, 1010, 2382, 2781, 3426, 1996, 4796, 3475, 1005, 1056, 4064, 1012, 1001, 8680, 7011, 4014, 1001, 3532, 24759, 11639, 2075, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "17",
         "1",
         "0.6875",
         "0.0",
         "{'input_ids': [101, 1030, 6892, 16558, 5657, 1045, 2106, 2156, 2008, 999, 2551, 2006, 8130, 2039, 1037, 4440, 2030, 2048, 2004, 2057, 2828, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "18",
         "0",
         "1.0",
         "1.0",
         "{'input_ids': [101, 1030, 25988, 4313, 1030, 7861, 15202, 19481, 2021, 2009, 2758, 2115, 6074, 2024, 2205, 5697, 1998, 2000, 3046, 2067, 2397, 3462, 2099, 1029, 1029, 1029, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "19",
         "0",
         "1.0",
         "0.6659",
         "{'input_ids': [101, 1030, 2142, 15536, 8873, 2347, 1005, 1056, 2551, 27120, 1012, 22333, 16742, 2128, 22278, 1012, 2017, 2741, 2033, 2000, 1037, 3309, 2005, 2484, 2847, 2007, 1021, 1002, 29536, 22368, 2015, 1029, 1029, 2053, 15536, 8873, 2012, 3309, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "20",
         "1",
         "1.0",
         "0.0",
         "{'input_ids': [101, 1030, 2142, 2057, 2018, 1037, 6919, 3462, 16742, 2315, 14188, 2008, 2001, 2007, 2149, 2013, 1048, 3654, 2000, 7939, 1010, 2059, 7939, 2000, 21086, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "21",
         "0",
         "1.0",
         "1.0",
         "{'input_ids': [101, 1030, 25988, 4313, 2115, 5887, 2050, 20220, 4366, 5126, 2323, 5382, 1037, 3531, 1010, 1037, 4067, 2017, 1998, 2019, 12480, 2064, 2175, 1037, 2146, 2126, 1001, 6304, 2121, 7903, 2063, 1001, 5887, 2050, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "22",
         "0",
         "0.6939",
         "0.3469",
         "{'input_ids': [101, 1030, 4943, 11215, 2129, 2515, 2115, 3653, 9405, 2832, 2147, 1029, 10468, 3087, 2040, 2987, 1005, 1056, 2215, 2000, 3524, 2037, 2735, 2064, 2131, 1037, 7540, 1029, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "23",
         "0",
         "1.0",
         "0.6609",
         "{'input_ids': [101, 1030, 4943, 11215, 2092, 1045, 2018, 1037, 2482, 1004, 23713, 1025, 2489, 2173, 1016, 2994, 2018, 1045, 2124, 21873, 3949, 2013, 11867, 15088, 2099, 1012, 8836, 1999, 6044, 1012, 1001, 9364, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "24",
         "0",
         "0.6319",
         "0.6319",
         "{'input_ids': [101, 1030, 4943, 11215, 2025, 2065, 2049, 3604, 4923, 2017, 2109, 2000, 4965, 1998, 2009, 4654, 20781, 2015, 2006, 1996, 2154, 2017, 2424, 1037, 2896, 3446, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "25",
         "0",
         "1.0",
         "0.696",
         "{'input_ids': [101, 1030, 2142, 2359, 2000, 1010, 2021, 2017, 8014, 3462, 3709, 2026, 9735, 1012, 1012, 1012, 1012, 2027, 2020, 2205, 2569, 1045, 3984, 2130, 2005, 2142, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "26",
         "1",
         "0.6676",
         "0.0",
         "{'input_ids': [101, 1030, 4943, 11215, 2115, 3626, 2006, 22997, 2620, 2003, 2725, 1037, 2307, 3105, 1997, 4363, 3071, 6727, 2076, 1996, 14350, 1001, 2507, 10760, 2213, 14995, 8583, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "27",
         "0",
         "1.0",
         "0.6882",
         "{'input_ids': [101, 1030, 2142, 2074, 2699, 2000, 8833, 1999, 1998, 2001, 2409, 1041, 1011, 5653, 8833, 1999, 2025, 2747, 2800, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "28",
         "1",
         "1.0",
         "0.0",
         "{'input_ids': [101, 1030, 4943, 11215, 2035, 1005, 1055, 2092, 1012, 1045, 2288, 4012, 5669, 2007, 3674, 2060, 8641, 2029, 2074, 2081, 2026, 2154, 999, 8299, 1024, 1013, 1013, 1056, 1012, 2522, 1013, 20720, 11431, 14550, 13699, 2232, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "29",
         "0",
         "1.0",
         "0.6823",
         "{'input_ids': [101, 1030, 4943, 11215, 2034, 2017, 2018, 1037, 2204, 2801, 2008, 15222, 2015, 2052, 4148, 1998, 2106, 2025, 8014, 3462, 2009, 3041, 1010, 2059, 2200, 5515, 4509, 2008, 2045, 2001, 2053, 2933, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "30",
         "1",
         "0.3414",
         "0.0",
         "{'input_ids': [101, 1030, 2142, 2043, 2024, 2017, 2746, 2067, 2000, 1030, 2065, 2135, 10441, 26086, 4859, 1029, 2017, 2031, 1037, 4121, 2264, 3016, 8013, 2918, 2349, 2000, 16420, 2080, 1998, 1008, 1045, 1008, 3335, 2017, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "31",
         "0",
         "1.0",
         "0.6845",
         "{'input_ids': [101, 1030, 2142, 3403, 2006, 4946, 2061, 2146, 4771, 2026, 7176, 3462, 2009, 2187, 2220, 1012, 2008, 1005, 1055, 1996, 2197, 3462, 2041, 3892, 1012, 2393, 8299, 1024, 1013, 1013, 1056, 1012, 2522, 1013, 1044, 5910, 3501, 2475, 22747, 16576, 2232, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "32",
         "1",
         "0.6481",
         "0.0",
         "{'input_ids': [101, 1030, 4943, 11215, 4129, 2026, 6904, 2213, 1999, 7136, 2085, 1012, 1024, 1007, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "33",
         "0",
         "1.0",
         "1.0",
         "{'input_ids': [101, 1030, 2142, 2003, 6429, 2129, 2524, 2003, 2000, 2831, 2007, 8013, 2326, 999, 999, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "34",
         "0",
         "1.0",
         "0.6667",
         "{'input_ids': [101, 1030, 2142, 2008, 3124, 2428, 2038, 2053, 8013, 2326, 9789, 1012, 2071, 2031, 2985, 3947, 8430, 8026, 2015, 2005, 11220, 15271, 2612, 1997, 2396, 3934, 1999, 3067, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "35",
         "0",
         "0.65",
         "0.3609",
         "{'input_ids': [101, 1030, 4943, 11215, 2026, 3129, 2003, 14120, 2000, 2032, 1998, 2002, 18292, 2000, 6366, 2032, 2013, 1996, 2835, 1012, 18411, 2860, 5751, 2024, 1999, 2119, 2394, 1998, 3009, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "36",
         "0",
         "1.0",
         "1.0",
         "{'input_ids': [101, 1030, 2142, 1045, 3246, 2061, 2021, 1045, 1005, 2310, 2363, 2053, 2393, 2061, 2521, 1012, 1045, 1005, 2310, 2042, 2006, 2907, 2005, 2062, 2084, 2019, 3178, 1012, 2064, 2619, 3713, 2000, 2033, 1029, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "37",
         "0",
         "1.0",
         "0.6952",
         "{'input_ids': [101, 1030, 3915, 4313, 14035, 4067, 2017, 1012, 1996, 4037, 12894, 2005, 2033, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "38",
         "1",
         "1.0",
         "0.0",
         "{'input_ids': [101, 4283, 2000, 1030, 4943, 11215, 1010, 1045, 2131, 2000, 2175, 2000, 1996, 1001, 7688, 7265, 7446, 2015, 1030, 8078, 29181, 5644, 2265, 2023, 5353, 1999, 6646, 1030, 2310, 23743, 12190, 3512, 999, 999, 999, 1001, 4067, 29337, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "39",
         "0",
         "1.0",
         "0.6646",
         "{'input_ids': [101, 1030, 25988, 4313, 1045, 1005, 2310, 2042, 1999, 2240, 2005, 2058, 2431, 3178, 2667, 2000, 2156, 1037, 4387, 1010, 2085, 1045, 2453, 2130, 3335, 1996, 2279, 3462, 2205, 1010, 21873, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "40",
         "1",
         "1.0",
         "0.0",
         "{'input_ids': [101, 1030, 2142, 13109, 2102, 6205, 2475, 1012, 14408, 11458, 2003, 6429, 999, 2234, 2041, 2077, 3462, 2000, 2377, 1000, 3198, 1996, 2952, 2505, 1012, 1000, 6919, 6059, 2000, 1996, 8582, 999, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "41",
         "0",
         "1.0",
         "0.6469",
         "{'input_ids': [101, 1030, 2142, 2115, 2047, 3542, 4270, 3343, 2003, 9643, 1012, 2077, 1010, 1045, 2453, 2031, 3825, 3621, 2062, 2005, 2142, 2138, 1997, 2661, 1012, 2085, 2045, 1005, 1055, 2053, 4489, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "42",
         "0",
         "1.0",
         "1.0",
         "{'input_ids': [101, 1030, 3915, 4313, 14035, 1016, 2847, 2006, 2907, 1012, 2145, 2053, 3437, 1012, 9202, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "43",
         "1",
         "0.3476",
         "0.0",
         "{'input_ids': [101, 1030, 4943, 11215, 2074, 2175, 3805, 1998, 2707, 1996, 8040, 10696, 11392, 5690, 2044, 1019, 7610, 2651, 2043, 2147, 2003, 2058, 1025, 1007, 1001, 7688, 7265, 7446, 2015, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "44",
         "0",
         "0.6907",
         "0.3711",
         "{'input_ids': [101, 1030, 4943, 11215, 1045, 2481, 1005, 1056, 4875, 2017, 2651, 1004, 23713, 1025, 2009, 2081, 1996, 4440, 6211, 1009, 2018, 2000, 3477, 2005, 2026, 7039, 4524, 1012, 1001, 7422, 2100, 29337, 2869, 2021, 2005, 2651, 1012, 1024, 1006, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "45",
         "0",
         "1.0",
         "0.6289",
         "{'input_ids': [101, 1030, 3915, 4313, 14035, 1045, 2097, 2196, 4875, 1030, 3915, 4313, 14035, 2153, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "46",
         "1",
         "1.0",
         "0.0",
         "{'input_ids': [101, 1030, 3915, 4313, 14035, 4283, 999, 8299, 1024, 1013, 1013, 1056, 1012, 2522, 1013, 22851, 2581, 2099, 2487, 3363, 2575, 2890, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "47",
         "0",
         "0.6476",
         "0.6476",
         "{'input_ids': [101, 1030, 6892, 16558, 5657, 1045, 2123, 1005, 1056, 2113, 1011, 2053, 2028, 2052, 2425, 2033, 2073, 2027, 2020, 2746, 2013, 1011, 1045, 2052, 3984, 2061, 2004, 2008, 1005, 1055, 2073, 2057, 2018, 2035, 1996, 3431, 2000, 7599, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "48",
         "1",
         "0.6858",
         "0.0",
         "{'input_ids': [101, 1030, 6261, 14074, 14735, 2178, 3819, 3462, 1012, 2129, 2272, 2006, 2115, 9738, 1010, 1996, 3103, 25292, 5668, 2064, 2994, 2091, 1029, 2060, 11363, 2191, 2017, 5333, 2068, 1029, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ],
        [
         "49",
         "0",
         "1.0",
         "0.6695",
         "{'input_ids': [101, 1030, 6892, 16558, 5657, 2821, 2157, 999, 2033, 1998, 3634, 2111, 3369, 2067, 2000, 1996, 2168, 4796, 2057, 2187, 2781, 3283, 1999, 17371, 4160, 8299, 1024, 1013, 1013, 1056, 1012, 2522, 1013, 1021, 18259, 2692, 25619, 2860, 22203, 2102, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 8078
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6654</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8073</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8074</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8075</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6448</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8076</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6649</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8077</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6947</td>\n",
       "      <td>0.3579</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8078 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment  airline_sentiment_confidence  \\\n",
       "0                     0                        1.0000   \n",
       "1                     1                        1.0000   \n",
       "2                     0                        0.7179   \n",
       "3                     0                        1.0000   \n",
       "4                     0                        1.0000   \n",
       "...                 ...                           ...   \n",
       "8073                  0                        1.0000   \n",
       "8074                  0                        1.0000   \n",
       "8075                  0                        1.0000   \n",
       "8076                  0                        1.0000   \n",
       "8077                  0                        0.6947   \n",
       "\n",
       "      negativereason_confidence                         text  \n",
       "0                        1.0000  [input_ids, attention_mask]  \n",
       "1                        0.0000  [input_ids, attention_mask]  \n",
       "2                        0.7179  [input_ids, attention_mask]  \n",
       "3                        0.6558  [input_ids, attention_mask]  \n",
       "4                        0.6654  [input_ids, attention_mask]  \n",
       "...                         ...                          ...  \n",
       "8073                     1.0000  [input_ids, attention_mask]  \n",
       "8074                     1.0000  [input_ids, attention_mask]  \n",
       "8075                     0.6448  [input_ids, attention_mask]  \n",
       "8076                     0.6649  [input_ids, attention_mask]  \n",
       "8077                     0.3579  [input_ids, attention_mask]  \n",
       "\n",
       "[8078 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis using pre-trained Bert-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7991341991341991\n",
      "precision score: 0.0\n",
      "recall score: 0.0\n",
      "f1 score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/howie/Competition/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "test_pred",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "test_true",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "predicted_confidences",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7ea62e4c-5291-4060-b172-935db3bcc694",
       "rows": [
        [
         "0",
         "0",
         "0",
         "0.52531713"
        ],
        [
         "1",
         "0",
         "0",
         "0.5177518"
        ],
        [
         "2",
         "0",
         "0",
         "0.5321297"
        ],
        [
         "3",
         "0",
         "0",
         "0.5300581"
        ],
        [
         "4",
         "0",
         "0",
         "0.519232"
        ],
        [
         "5",
         "0",
         "0",
         "0.53395474"
        ],
        [
         "6",
         "0",
         "0",
         "0.5228365"
        ],
        [
         "7",
         "0",
         "0",
         "0.52599555"
        ],
        [
         "8",
         "0",
         "0",
         "0.5357192"
        ],
        [
         "9",
         "0",
         "0",
         "0.51782393"
        ],
        [
         "10",
         "0",
         "0",
         "0.51642525"
        ],
        [
         "11",
         "0",
         "1",
         "0.52212656"
        ],
        [
         "12",
         "0",
         "0",
         "0.5178713"
        ],
        [
         "13",
         "0",
         "0",
         "0.5347083"
        ],
        [
         "14",
         "0",
         "0",
         "0.5350675"
        ],
        [
         "15",
         "0",
         "0",
         "0.53192806"
        ],
        [
         "16",
         "0",
         "0",
         "0.52329636"
        ],
        [
         "17",
         "0",
         "0",
         "0.5321577"
        ],
        [
         "18",
         "0",
         "0",
         "0.5351999"
        ],
        [
         "19",
         "0",
         "0",
         "0.53200805"
        ],
        [
         "20",
         "0",
         "1",
         "0.52614397"
        ],
        [
         "21",
         "0",
         "1",
         "0.5267905"
        ],
        [
         "22",
         "0",
         "0",
         "0.5166729"
        ],
        [
         "23",
         "0",
         "1",
         "0.5283775"
        ],
        [
         "24",
         "0",
         "0",
         "0.52785456"
        ],
        [
         "25",
         "0",
         "0",
         "0.53277606"
        ],
        [
         "26",
         "0",
         "0",
         "0.53295064"
        ],
        [
         "27",
         "0",
         "0",
         "0.51799667"
        ],
        [
         "28",
         "0",
         "0",
         "0.5231238"
        ],
        [
         "29",
         "0",
         "0",
         "0.5238073"
        ],
        [
         "30",
         "0",
         "0",
         "0.5235099"
        ],
        [
         "31",
         "0",
         "0",
         "0.527748"
        ],
        [
         "32",
         "0",
         "0",
         "0.52468884"
        ],
        [
         "33",
         "0",
         "0",
         "0.5217409"
        ],
        [
         "34",
         "0",
         "0",
         "0.53252876"
        ],
        [
         "35",
         "0",
         "0",
         "0.52296424"
        ],
        [
         "36",
         "0",
         "0",
         "0.53125465"
        ],
        [
         "37",
         "0",
         "0",
         "0.53236353"
        ],
        [
         "38",
         "0",
         "1",
         "0.5285266"
        ],
        [
         "39",
         "0",
         "0",
         "0.5349936"
        ],
        [
         "40",
         "0",
         "0",
         "0.52871114"
        ],
        [
         "41",
         "0",
         "0",
         "0.52848643"
        ],
        [
         "42",
         "0",
         "0",
         "0.5290839"
        ],
        [
         "43",
         "0",
         "1",
         "0.5419202"
        ],
        [
         "44",
         "0",
         "0",
         "0.53624773"
        ],
        [
         "45",
         "0",
         "0",
         "0.52774495"
        ],
        [
         "46",
         "0",
         "0",
         "0.5297546"
        ],
        [
         "47",
         "0",
         "0",
         "0.5221851"
        ],
        [
         "48",
         "0",
         "1",
         "0.52207416"
        ],
        [
         "49",
         "0",
         "0",
         "0.52584624"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 1155
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_pred</th>\n",
       "      <th>test_true</th>\n",
       "      <th>predicted_confidences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.517752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.532130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.531278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.532974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1155 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_pred  test_true  predicted_confidences\n",
       "0             0          0               0.525317\n",
       "1             0          0               0.517752\n",
       "2             0          0               0.532130\n",
       "3             0          0               0.530058\n",
       "4             0          0               0.519232\n",
       "...         ...        ...                    ...\n",
       "1150          0          1               0.518085\n",
       "1151          0          1               0.518094\n",
       "1152          0          0               0.531278\n",
       "1153          0          0               0.532974\n",
       "1154          0          0               0.515874\n",
       "\n",
       "[1155 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize testing text\n",
    "test_input = tokenizer(list(corpus_test['text']), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**test_input)\n",
    "    logits = outputs.logits  # shape: (batch_size, num_labels)\n",
    "\n",
    "# Convert logits to probabilities\n",
    "probabilities = torch.softmax(logits, dim=-1)\n",
    "# Assume index 0 is negative and 1 is positive\n",
    "predicted_labels = torch.argmax(probabilities, dim=-1).numpy()\n",
    "# Confidence can be taken as the probability of the predicted label\n",
    "predicted_confidences = probabilities.max(dim=-1).values.numpy()\n",
    "# true label from corpus_test\n",
    "test_true = corpus_test['airline_sentiment']\n",
    "\n",
    "initial_result = pd.DataFrame({\n",
    "    'test_pred': predicted_labels,\n",
    "    'test_true': corpus_test['airline_sentiment'],\n",
    "    'predicted_confidences': predicted_confidences\n",
    "})\n",
    "\n",
    "print(f'accuracy score: {accuracy_score(test_true, predicted_labels)}')\n",
    "print(f'precision score: {precision_score(test_true, predicted_labels)}')\n",
    "print(f'recall score: {recall_score(test_true, predicted_labels)}')\n",
    "print(f'f1 score: {f1_score(test_true, predicted_labels)}')\n",
    "\n",
    "\n",
    "initial_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label\n",
    "1 means good\n",
    "0 means bad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the Bert-based LLM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the training and validating corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 2308\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new columns for input_ids and attention_mask for training data\n",
    "corpus_train[\"input_ids\"] = corpus_train[\"text\"].apply(lambda x: x[\"input_ids\"])\n",
    "corpus_train[\"attention_mask\"] = corpus_train[\"text\"].apply(lambda x: x[\"attention_mask\"])\n",
    "corpus_train = corpus_train.rename(columns={\"airline_sentiment\": \"labels\"})\n",
    "\n",
    "train_dataset = Dataset.from_pandas(corpus_train[['input_ids','attention_mask','labels']])\n",
    "train_dataset\n",
    "\n",
    "# Create new columns for input_ids and attention_mask for validation data\n",
    "corpus_val['text'] = corpus_val['text'].apply(lambda x: tokenizer(x, truncation=True))\n",
    "\n",
    "corpus_val[\"input_ids\"] = corpus_val[\"text\"].apply(lambda x: x[\"input_ids\"])\n",
    "corpus_val[\"attention_mask\"] = corpus_val[\"text\"].apply(lambda x: x[\"attention_mask\"])\n",
    "corpus_val = corpus_val.rename(columns={\"airline_sentiment\": \"labels\"})\n",
    "\n",
    "eval_dataset = Dataset.from_pandas(corpus_val[['input_ids','attention_mask','labels']])\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(trial):\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",             \n",
    "    eval_strategy=\"epoch\",       \n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=4,                \n",
    "    weight_decay=0.02,\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, predictions),\n",
    "        \"precision\": precision_score(labels, predictions),\n",
    "        \"recall\": recall_score(labels, predictions),\n",
    "        \"f1\": f1_score(labels, predictions)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[I 2025-04-03 17:20:34,730] A new study created in memory with name: no-name-cc274afd-61ea-49f1-bebb-0b139cc28d81\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 10:40, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>0.160711</td>\n",
       "      <td>0.940641</td>\n",
       "      <td>0.887892</td>\n",
       "      <td>0.819876</td>\n",
       "      <td>0.852530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.116400</td>\n",
       "      <td>0.189629</td>\n",
       "      <td>0.944541</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.879917</td>\n",
       "      <td>0.869121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.280112</td>\n",
       "      <td>0.941941</td>\n",
       "      <td>0.924574</td>\n",
       "      <td>0.786749</td>\n",
       "      <td>0.850112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.260080</td>\n",
       "      <td>0.947574</td>\n",
       "      <td>0.878661</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.874089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 17:31:16,766] Trial 0 finished with value: 3.569889452217631 and parameters: {'learning_rate': 2.4460807789600356e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.04}. Best is trial 0 with value: 3.569889452217631.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1012' max='1012' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1012/1012 08:54, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.158662</td>\n",
       "      <td>0.938042</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.817805</td>\n",
       "      <td>0.846731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.151300</td>\n",
       "      <td>0.172734</td>\n",
       "      <td>0.933276</td>\n",
       "      <td>0.906173</td>\n",
       "      <td>0.759834</td>\n",
       "      <td>0.826577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.166044</td>\n",
       "      <td>0.943241</td>\n",
       "      <td>0.891111</td>\n",
       "      <td>0.830228</td>\n",
       "      <td>0.859593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.107700</td>\n",
       "      <td>0.170679</td>\n",
       "      <td>0.945841</td>\n",
       "      <td>0.889130</td>\n",
       "      <td>0.846791</td>\n",
       "      <td>0.867444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 17:40:12,164] Trial 1 finished with value: 3.54920620626166 and parameters: {'learning_rate': 1.009878008407478e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.08}. Best is trial 0 with value: 3.569889452217631.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1515' max='1515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1515/1515 08:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.172021</td>\n",
       "      <td>0.937175</td>\n",
       "      <td>0.891204</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.841530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.192146</td>\n",
       "      <td>0.944107</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.832298</td>\n",
       "      <td>0.861736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.208719</td>\n",
       "      <td>0.946707</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.861284</td>\n",
       "      <td>0.871204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 17:48:36,473] Trial 2 finished with value: 3.560550870296642 and parameters: {'learning_rate': 1.954061681564862e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.06}. Best is trial 0 with value: 3.569889452217631.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [759/759 06:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.148546</td>\n",
       "      <td>0.941508</td>\n",
       "      <td>0.876623</td>\n",
       "      <td>0.838509</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.118300</td>\n",
       "      <td>0.153738</td>\n",
       "      <td>0.948007</td>\n",
       "      <td>0.885350</td>\n",
       "      <td>0.863354</td>\n",
       "      <td>0.874214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.174107</td>\n",
       "      <td>0.948007</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.850932</td>\n",
       "      <td>0.872611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 17:55:31,816] Trial 3 finished with value: 3.566974910997106 and parameters: {'learning_rate': 2.099142871148337e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 32, 'weight_decay': 0.08}. Best is trial 0 with value: 3.569889452217631.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 1:40:44, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>0.164156</td>\n",
       "      <td>0.940208</td>\n",
       "      <td>0.900232</td>\n",
       "      <td>0.803313</td>\n",
       "      <td>0.849015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.198737</td>\n",
       "      <td>0.943241</td>\n",
       "      <td>0.846457</td>\n",
       "      <td>0.890269</td>\n",
       "      <td>0.867810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.264436</td>\n",
       "      <td>0.944541</td>\n",
       "      <td>0.904328</td>\n",
       "      <td>0.821946</td>\n",
       "      <td>0.861171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.270019</td>\n",
       "      <td>0.949307</td>\n",
       "      <td>0.887712</td>\n",
       "      <td>0.867495</td>\n",
       "      <td>0.877487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:36:17,196] Trial 4 finished with value: 3.582000358516894 and parameters: {'learning_rate': 3.193442013911449e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'weight_decay': 0.1}. Best is trial 4 with value: 3.582000358516894.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='759' max='1012' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 759/1012 06:35 < 02:12, 1.91 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.184600</td>\n",
       "      <td>0.149433</td>\n",
       "      <td>0.939341</td>\n",
       "      <td>0.864119</td>\n",
       "      <td>0.842650</td>\n",
       "      <td>0.853249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.155086</td>\n",
       "      <td>0.942808</td>\n",
       "      <td>0.875803</td>\n",
       "      <td>0.846791</td>\n",
       "      <td>0.861053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.204242</td>\n",
       "      <td>0.941941</td>\n",
       "      <td>0.918465</td>\n",
       "      <td>0.792961</td>\n",
       "      <td>0.851111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:43:03,921] Trial 5 pruned. \n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1515' max='1515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1515/1515 08:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.195300</td>\n",
       "      <td>0.161547</td>\n",
       "      <td>0.943674</td>\n",
       "      <td>0.886214</td>\n",
       "      <td>0.838509</td>\n",
       "      <td>0.861702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.187438</td>\n",
       "      <td>0.947574</td>\n",
       "      <td>0.873967</td>\n",
       "      <td>0.875776</td>\n",
       "      <td>0.874871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>0.212914</td>\n",
       "      <td>0.949307</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.877743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:51:26,627] Trial 6 finished with value: 3.5826908725656437 and parameters: {'learning_rate': 2.3253091959105992e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.02}. Best is trial 6 with value: 3.5826908725656437.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1515' max='1515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1515/1515 08:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>0.164064</td>\n",
       "      <td>0.942808</td>\n",
       "      <td>0.871036</td>\n",
       "      <td>0.853002</td>\n",
       "      <td>0.861925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.196816</td>\n",
       "      <td>0.946707</td>\n",
       "      <td>0.873444</td>\n",
       "      <td>0.871636</td>\n",
       "      <td>0.872539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.236653</td>\n",
       "      <td>0.944541</td>\n",
       "      <td>0.881720</td>\n",
       "      <td>0.848861</td>\n",
       "      <td>0.864979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 20:00:06,004] Trial 7 finished with value: 3.540101344607952 and parameters: {'learning_rate': 2.9047684378642023e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.04}. Best is trial 6 with value: 3.5826908725656437.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='505' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 505/2020 1:41:46 < 5:06:33, 0.08 it/s, Epoch 1/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.183600</td>\n",
       "      <td>0.163962</td>\n",
       "      <td>0.940641</td>\n",
       "      <td>0.894977</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.851249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 21:41:54,380] Trial 8 pruned. \n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='505' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 505/2020 02:39 < 08:00, 3.15 it/s, Epoch 1/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>0.160644</td>\n",
       "      <td>0.940208</td>\n",
       "      <td>0.930175</td>\n",
       "      <td>0.772257</td>\n",
       "      <td>0.843891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 21:44:44,810] Trial 9 pruned. \n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=None,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    eval_dataset=eval_dataset,\n",
    "    model_init = model_init\n",
    ")\n",
    "\n",
    "# Define the hyperparameter search space using an Optuna trial\n",
    "def hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-5,log=True),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 3, 5),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32]),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.1, step=0.02),\n",
    "    }\n",
    "\n",
    "best_run = trainer.hyperparameter_search(\n",
    "    hp_space=hp_space,\n",
    "    backend=\"optuna\",\n",
    "    n_trials=10,            # Adjust number of trials as needed\n",
    "    direction=\"maximize\"    # Here we maximize the evaluation accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 2.3253091959105992e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.02}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters:\", best_run.hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1515' max='1515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1515/1515 08:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.195200</td>\n",
       "      <td>0.161653</td>\n",
       "      <td>0.944541</td>\n",
       "      <td>0.890110</td>\n",
       "      <td>0.838509</td>\n",
       "      <td>0.863539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.187128</td>\n",
       "      <td>0.947574</td>\n",
       "      <td>0.873967</td>\n",
       "      <td>0.875776</td>\n",
       "      <td>0.874871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>0.212917</td>\n",
       "      <td>0.949307</td>\n",
       "      <td>0.887712</td>\n",
       "      <td>0.867495</td>\n",
       "      <td>0.877487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1515, training_loss=0.13110034450052596, metrics={'train_runtime': 480.7381, 'train_samples_per_second': 50.41, 'train_steps_per_second': 3.151, 'total_flos': 280740848715696.0, 'train_loss': 0.13110034450052596, 'epoch': 3.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update parameters with the best parameters \n",
    "trainer.args.learning_rate = best_run.hyperparameters[\"learning_rate\"]\n",
    "trainer.args.num_train_epochs = best_run.hyperparameters[\"num_train_epochs\"]\n",
    "trainer.args.per_device_train_batch_size = best_run.hyperparameters[\"per_device_train_batch_size\"]\n",
    "trainer.args.weight_decay = best_run.hyperparameters[\"weight_decay\"]\n",
    "\n",
    "# re-train using best parameters\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 1155\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new columns for input_ids and attention_mask for testing data\n",
    "corpus_test['text'] = corpus_test['text'].apply(lambda x: tokenizer(x, truncation=True))\n",
    "\n",
    "corpus_test[\"input_ids\"] = corpus_test[\"text\"].apply(lambda x: x[\"input_ids\"])\n",
    "corpus_test[\"attention_mask\"] = corpus_test[\"text\"].apply(lambda x: x[\"attention_mask\"])\n",
    "corpus_test = corpus_test.rename(columns={\"airline_sentiment\": \"labels\"})\n",
    "\n",
    "test_dataset = Dataset.from_pandas(corpus_test[['input_ids','attention_mask']])\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.9506493506493506\n",
      "precision score: 0.8854625550660793\n",
      "recall score: 0.8663793103448276\n",
      "f1 score: 0.8758169934640523\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "test_pred",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "test_true",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "predicted_confidences",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7405e635-3d0c-49e6-8fc2-14d62b8e194c",
       "rows": [
        [
         "0",
         "0",
         "0",
         "0.99886537"
        ],
        [
         "1",
         "0",
         "0",
         "0.9985139"
        ],
        [
         "2",
         "0",
         "0",
         "0.99907124"
        ],
        [
         "3",
         "0",
         "0",
         "0.9985208"
        ],
        [
         "4",
         "0",
         "0",
         "0.9990324"
        ],
        [
         "5",
         "0",
         "0",
         "0.99846053"
        ],
        [
         "6",
         "0",
         "0",
         "0.9382777"
        ],
        [
         "7",
         "0",
         "0",
         "0.99893326"
        ],
        [
         "8",
         "1",
         "0",
         "0.9776839"
        ],
        [
         "9",
         "0",
         "0",
         "0.9992204"
        ],
        [
         "10",
         "0",
         "0",
         "0.99909055"
        ],
        [
         "11",
         "1",
         "1",
         "0.9983607"
        ],
        [
         "12",
         "0",
         "0",
         "0.99904007"
        ],
        [
         "13",
         "0",
         "0",
         "0.9991855"
        ],
        [
         "14",
         "0",
         "0",
         "0.99916875"
        ],
        [
         "15",
         "0",
         "0",
         "0.99912506"
        ],
        [
         "16",
         "0",
         "0",
         "0.9988457"
        ],
        [
         "17",
         "0",
         "0",
         "0.9992494"
        ],
        [
         "18",
         "0",
         "0",
         "0.99894124"
        ],
        [
         "19",
         "0",
         "0",
         "0.99863726"
        ],
        [
         "20",
         "1",
         "1",
         "0.9981864"
        ],
        [
         "21",
         "1",
         "1",
         "0.99805707"
        ],
        [
         "22",
         "0",
         "0",
         "0.9991466"
        ],
        [
         "23",
         "1",
         "1",
         "0.998343"
        ],
        [
         "24",
         "0",
         "0",
         "0.9983236"
        ],
        [
         "25",
         "0",
         "0",
         "0.99910396"
        ],
        [
         "26",
         "0",
         "0",
         "0.9992538"
        ],
        [
         "27",
         "0",
         "0",
         "0.999154"
        ],
        [
         "28",
         "0",
         "0",
         "0.9991642"
        ],
        [
         "29",
         "0",
         "0",
         "0.9991584"
        ],
        [
         "30",
         "0",
         "0",
         "0.9988513"
        ],
        [
         "31",
         "0",
         "0",
         "0.998563"
        ],
        [
         "32",
         "0",
         "0",
         "0.9985903"
        ],
        [
         "33",
         "0",
         "0",
         "0.9990939"
        ],
        [
         "34",
         "0",
         "0",
         "0.9982886"
        ],
        [
         "35",
         "0",
         "0",
         "0.99900454"
        ],
        [
         "36",
         "0",
         "0",
         "0.9989681"
        ],
        [
         "37",
         "0",
         "0",
         "0.99820197"
        ],
        [
         "38",
         "1",
         "1",
         "0.6045286"
        ],
        [
         "39",
         "0",
         "0",
         "0.9992016"
        ],
        [
         "40",
         "0",
         "0",
         "0.9979221"
        ],
        [
         "41",
         "0",
         "0",
         "0.9609172"
        ],
        [
         "42",
         "0",
         "0",
         "0.99560577"
        ],
        [
         "43",
         "0",
         "1",
         "0.9858328"
        ],
        [
         "44",
         "0",
         "0",
         "0.99824667"
        ],
        [
         "45",
         "0",
         "0",
         "0.9992648"
        ],
        [
         "46",
         "0",
         "0",
         "0.9894968"
        ],
        [
         "47",
         "0",
         "0",
         "0.99896073"
        ],
        [
         "48",
         "1",
         "1",
         "0.93277"
        ],
        [
         "49",
         "0",
         "0",
         "0.9985947"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 1155
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_pred</th>\n",
       "      <th>test_true</th>\n",
       "      <th>predicted_confidences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1155 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_pred  test_true  predicted_confidences\n",
       "0             0          0               0.998865\n",
       "1             0          0               0.998514\n",
       "2             0          0               0.999071\n",
       "3             0          0               0.998521\n",
       "4             0          0               0.999032\n",
       "...         ...        ...                    ...\n",
       "1150          1          1               0.996202\n",
       "1151          1          1               0.992641\n",
       "1152          0          0               0.999115\n",
       "1153          0          0               0.999262\n",
       "1154          0          0               0.998436\n",
       "\n",
       "[1155 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions as a numpy array\n",
    "predictions_np = trainer.predict(test_dataset).predictions\n",
    "\n",
    "# Convert the numpy array to a torch tensor and then apply softmax\n",
    "predictions_tensor = torch.tensor(predictions_np)\n",
    "probabilities = torch.softmax(predictions_tensor, dim=-1)\n",
    "predicted_labels = torch.argmax(probabilities, dim=-1).numpy()\n",
    "predicted_confidences = probabilities.max(dim=-1).values.numpy()\n",
    "\n",
    "final_result = pd.DataFrame({\n",
    "    'test_pred': predicted_labels,\n",
    "    'test_true': corpus_test['labels'],\n",
    "    'predicted_confidences': predicted_confidences\n",
    "})\n",
    "\n",
    "print(f'accuracy score: {accuracy_score(test_true, predicted_labels)}')\n",
    "print(f'precision score: {precision_score(test_true, predicted_labels)}')\n",
    "print(f'recall score: {recall_score(test_true, predicted_labels)}')\n",
    "print(f'f1 score: {f1_score(test_true, predicted_labels)}')\n",
    "\n",
    "final_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
